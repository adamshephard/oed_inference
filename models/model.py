import numpy as np
import torch
from torch import nn
import torch.nn.functional as F  # noqa: N812
from tiatoolbox.models.models_abc import ModelABC
from tiatoolbox.utils import misc
from collections import OrderedDict

from .transunet.vit_seg_model import VisionTransformer as ViT_seg
from .transunet.vit_seg_model import CONFIGS as CONFIGS_ViT_seg
from .utils import convert_pytorch_checkpoint, crop_op


class TransUNet(ModelABC):
    def __init__(self: ModelABC,
                 weights=None,
                 nr_layers=None,
                 img_size=512,
                 patch_size=16
        ) -> None:
        super().__init__()
        self.nr_layers = nr_layers
        encoder_backbone_name = "R50-ViT-B_16"
        config_vit = CONFIGS_ViT_seg[encoder_backbone_name]
        config_vit.n_classes = nr_layers
        config_vit.n_skip = 3
        if encoder_backbone_name.find('R50') != -1:
            config_vit.patches.grid = (int(img_size / patch_size), int(img_size / patch_size))
        self.model = ViT_seg(config_vit, img_size=img_size, num_classes=nr_layers, freeze=False).cuda()
        if weights is not None:
            saved_state_dict = torch.load(weights)["desc"]
            saved_state_dict = convert_pytorch_checkpoint(saved_state_dict)
            self.model.load_state_dict(saved_state_dict, strict=False) 


    def forward(self: ModelABC, img_list: list) -> torch.nn.Module:
        """Model forward function."""
        # must be rgb input
        imgs = img_list / 255.0  # to 0-1 range
        out = self.model(imgs)
        # out = crop_op(out, [92, 92])
        out = crop_op(out, [184, 184])
        out_dict = OrderedDict()
        out_dict['ls'] = out
        return out_dict

# @staticmethod
#     # skipcq: PYL-W0221  # noqa: ERA001
#     def postproc(raw_maps: list[np.ndarray]) -> tuple[np.ndarray, dict]:
#         """Post-processing script for image tiles.

#         Args:
#             raw_maps (list(:class:`numpy.ndarray`)):
#                 A list of prediction outputs of each head and assumed to
#                 be in the order of [ls] (match with the output
#                 of `infer_batch`).

#         Returns:
#             tuple:
#                 - :class:`numpy.ndarray` - Layer map:
#                     Pixel-wise nuclear layer segmentation prediction.

#         """
#         ls_map = raw_maps
#         return ls_map
    
    @staticmethod
    def infer_batch(model: nn.Module, batch_data: np.ndarray, on_gpu: bool) -> np.ndarray:
    # def infer_batch(model: nn.Module, batch_data: np.ndarray, *, on_gpu: bool) -> np.ndarray:
        """Run inference on an input batch.

        This contains logic for forward operation as well as batch i/o
        aggregation.

        Args:
            model (nn.Module):
                PyTorch defined model.
            batch_data (ndarray):
                A batch of data generated by
                `torch.utils.data.DataLoader`.
            on_gpu (bool):
                Whether to run inference on a GPU.

        Returns:
            tuple:
                Output from each head. Each head is expected to contain
                N predictions for N input patches.

        """
        patch_imgs = batch_data

        device = misc.select_device(on_gpu=on_gpu)
        patch_imgs_gpu = patch_imgs.to(device).type(torch.float32)  # to NCHW
        patch_imgs_gpu = patch_imgs_gpu.permute(0, 3, 1, 2).contiguous()

        model.eval()  # infer mode

        # --------------------------------------------------------------
        with torch.inference_mode():
            pred_dict = model(patch_imgs_gpu)
            pred_dict = OrderedDict(
                [[k, v.permute(0, 2, 3, 1).contiguous()] for k, v in pred_dict.items()],
            )
            if "ls" in pred_dict:
                layer_map = F.softmax(pred_dict["ls"], dim=-1)
                # layer_map = pred_dict["ls"][...,1]
                # layer_map = torch.argmax(layer_map, dim=-1, keepdim=True)
                # layer_map = layer_map.type(torch.float32)
                pred_dict["ls"] = layer_map
            # if pred_vendor is not None:
            #     pred_dict["vendor"] = pred_vendor
            pred_output = torch.cat(list(pred_dict.values()), -1)
        return pred_output.cpu().numpy()

